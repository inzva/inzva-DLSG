# inzvaDSLG

# Introduction
The inzva Deep Learning Study Group (DLSG) serves as an essential guide for anyone looking to get started in the deep learning field. It not only offers a comprehensive introduction but also forms the backbone of our most fundamental study group, making it a critical resource for both beginners and those looking to deepen their knowledge. We extend our heartfelt thanks to all the contributors and volunteers of our community who have dedicated their time and effort to create and compile these invaluable resources. Their hard work has made this project possible, ensuring that the materials are accessible and beneficial to a wide range of learners. Every decision, from the content selection to the structure, has been made with great care and consideration.

This repository is not just a static collection of information but a living document that will be regularly updated to stay in line with the fast-paced developments in artificial intelligence. We hope this guide will serve as a cornerstone for anyone who is passionate about deep learning, inspiring further exploration.

# Syllabus and Materials

<table>
    <thead>
        <tr>
            <th>Weeks</th>
            <th>Course Name</th>
            <th>Topic</th>
            <th>Bundle</th>
            <th>Slide</th>
            <th>Notebooks</th>
            <th>Recommended Links</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <th colspan=7> inzva Deep Learning Study Group</th>
        </tr>
        <tr>
            <td style="text-align: center;"rowspan=2> <b>w1</b> </td>
            <td style="text-align: center;"rowspan=2>Introduction to inzva DLSG</td>
            <td>Introduction to the Course</td>
            <td style="text-align: center;"rowspan=2><a href="https://drive.google.com/file/d/1Ce9VyWxFiW0EBYicveAVOJp25jyPg_W8/view?usp=drive_link">intro_nns</a></td>
            <td style="text-align: center;"rowspan=2><a href="https://drive.google.com/file/d/1LhQq9k6Ik8AiE6foAO6r-SjvpFacDtIt/view?usp=sharing">w1_s</a></td>
            <td style="text-align: center;"rowspan=2><a href="https://drive.google.com/file/d/1sGPepXg0tkQC1bi5IzWhwOyjjGr9MCfx/view?usp=sharing">pytorchintro</a> <a href="https://drive.google.com/file/d/1BbhAnr0pD3_h-NVcNf_mx5hi-69jdEtC/view?usp=sharing">train_fcn</a> <a href="https://drive.google.com/file/d/1gIRoHE5ZHqd0UElQYmHokbkJorKfF4UO/view?usp=sharing">test_fcn</a></td>
            <td> </td>
        </tr>
        <tr>
            <td>Introduction to Neural Networks</td>
			  <td>
            <a href="https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">[3b1b-1]</a> <br>
            <a href="https://www.youtube.com/watch?v=IHZwWFHWa-w&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=2">[3b1b-2]</a>  <br>
            <a href="https://www.youtube.com/watch?v=Ilg3gGewQ5U&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=3">[3b1b-3]</a>  <br>
            <a href="https://www.youtube.com/watch?v=tIeHLnjs5U8&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=4">[3b1b-4]</a>  <br>
            <a href="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/">[UAT]</a> 
            </td>
        </tr>
        <tr>
            <td style="text-align: center;"> <b>w2</b> </td>
            <td style="text-align: center;"rowspan=2>Improving Deep Neural Networks:
 Hyperparameter tuning, Regularization and Optimization</td>
            <td>Hyperparameter Tuning and Regularization Methods</td>
            <td><a href="https://drive.google.com/file/d/1dtsZPtXomEv7qxDcMP2NBQrLGiV7JNLM/view?usp=sharing">handbook</a></td>
            <td><a href="https://drive.google.com/file/d/1jVCtRNULfGDzOqizoNMr9Pr-rjPQ3FVt/view?usp=sharing">w2_s</a></td>
            <td><a href="https://drive.google.com/file/d/1jtKAdJtjT4bium2gISp5NiiXwtj1fzA4/view?usp=sharing">exercise</a> <a href="https://drive.google.com/file/d/1_wAY84_yrIyvlMDqhpm1xsYmuzmzj5rC/view?usp=sharing">soln</a> </td>
            <td><a href=""></a><a href=""></a></td>
        </tr>
        <tr>
            <td style="text-align: center;"> <b>w3</b> </td>
            <td>Optimization Algorithms</td>
            <td><a href="https://drive.google.com/file/d/1q9ub7NMhkxM8ugopzBLpAAesyb2uy3uI/view?usp=sharing">optimization_algos</a></td>
            <td><a href="https://drive.google.com/file/d/1-wVi_odVzSnaWIUD4gLo7z5OzzAdK1gg/view?usp=sharing">w3_s</a></td>
            <td><a href="https://drive.google.com/file/d/1cF-1bWmH7hfPxLWOSEzUx2I9jf6v__3C/view?usp=sharing">example</a></td>
            <td><a href="https://www.youtube.com/watch?v=NE88eqLngkg">[1]</a> <a href=""></a></td>
        </tr>
        <tr>
            <th colspan=7> Homework-1</th>
        </tr>
        <tr>
            <td style="text-align: center;"> <b>w4</b> </td>
            <td style="text-align: center;"rowspan=6>Neural Network Architectures and Common Tasks in Deep Learning</td>
            <td rowspan=2>Convolutional Neural Networks with Common Tasks: Image Classification, Object Detection, Image Segmentation</td>
            <td rowspan=2><a href="https://drive.google.com/file/d/15G76dE5UhGSYNAtZSQpbCcNtkeH0vPuZ/view?usp=sharing">conv_nns</a></td>
            <td><a href="https://drive.google.com/file/d/1pG3aLVz8t0VKjppymQ8iA6b-Qo3YsCUX/view?usp=sharing">w4_s</a></td>
            <td><a href="https://drive.google.com/file/d/1dApDs65P0ORibXJtgsocG5VGZI9B2DP3/view?usp=sharing">materials</a></td>
            <td><a href="https://www.youtube.com/watch?v=KuXjwB4LzSA&t=566s">[3b1b-5]</a> 
            <a href="https://www.youtube.com/watch?v=IaSGqQa5O-M">[3b1b-6]</a> 
            <a href="https://www.youtube.com/watch?v=pj9-rr1wDhM">[F]</a> 
            <a href="https://www.youtube.com/watch?v=jDe5BAsT2-Y">[4]</a></td>
        </tr>
        <tr>
            <td style="text-align: center;"> <b>w5</b> </td>
            <td><a href="https://github.com/denizberkin/study_group_week5/tree/final"></a></td>
            <td><a href="https://github.com/denizberkin/study_group_week5/tree/final">materials</a></td>
            <td><a href=""></a> <a href=""></a></td>
        </tr>
        <tr>
            <td style="text-align: center;"> <b>w6</b> </td>
            <td rowspan=2>Recurrent Neural Networks with Common Tasks: Natural Language Processing</td>
            <td rowspan=2 ><a href="https://drive.google.com/file/d/1Yckxlqqo1EF1PlyhwKuvHq4l9byg2etK/view?usp=sharing">nlp_handbook</a></td>
            <td><a href="https://drive.google.com/file/d/1AkDNkLoOWIgh0Qyoxmve1Qh4UjsBBWUd/view?usp=sharing">w6_s</a></td>
            <td><a href=""></a></td>
            <td><a href=""></a> <a href=""></a></td>
        </tr>
        <tr>
            <td style="text-align: center;"> <b>w7</b> </td>
            <td><a href=""></a></td>
            <td><a href="https://drive.google.com/drive/folders/1fkLk5DUHXqgURQ-ekojGygr3gKrKCEkp?usp=sharing">link</a></td>
            <td><a href=""></a> <a href=""></a></td>
        </tr>
        <tr>
            <td style="text-align: center;"> <b>w8</b> </td>
            <td rowspan=2 >Transformers with Common Tasks: Machine Translation, Image Classification</td>
            <td rowspan=2 ><a href="https://drive.google.com/file/d/1bViI6MQ5wTijwaUp5N5Ahm0KrDjkcP8k/view?usp=sharing">transformers</a></td>
            <td><a href="https://drive.google.com/file/d/1ykSjVS7gkNO7qFbc-Mndhp-AovtLlYUf/view?usp=sharing">w8_s</a></td>
            <td><a href=""></a></td>
            <td>
            <a href="https://jalammar.github.io/illustrated-transformer/">[IT]</a>
            <br>
            <a href="https://www.youtube.com/watch?v=yGTUuEx3GkA&t=1s">[RASA-1]</a>
            <br>
            <a href="https://www.youtube.com/watch?v=tIvKXrEDMhk">[RASA-2]</a>
            <br>
            <a href="https://www.youtube.com/watch?v=23XUv0T9L5c">[RASA-3]</a>
            <br>
            <a href="https://www.youtube.com/watch?v=EXNBy8G43MM">[RASA-4]</a>
            <br>
			  <a href="https://www.youtube.com/watch?v=eMlx5fFNoYc">[ATN-3b1b]</a>
            </td>
        </tr>
        <tr>
            <td style="text-align: center;"> <b>w9</b> </td>
            <td><a href=""></a></td> <!-- w9 slide -->
            <td><a href="https://www.kaggle.com/code/berfinduman0/inzva-vit-example">vit</a> <a href="https://www.kaggle.com/code/berfinduman0/eng-tr-neural-translation-dive-into-transformers">nmt</a></td> <!-- w9 notebook -->
            <td>
            <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">[NMT]</a> 
            </td>
        </tr>
        <tr>
            <th colspan=7> Homework-2</th>
        </tr>
        <tr>
            <td style="text-align: center;"> <b>w10</b> </td>
 			  <td rowspan=3> Trend Topics in Deep Learning</td>
 			  <td rowspan=1> Generative Models (VAEs, Diffusion Models)</td>
 			  <td><a href="https://drive.google.com/file/d/1Zx5V8vT2NosDXmhPYQ0l47Eh_5--mZTz/view?usp=sharing">intro_genai</a></td>
 			  <td><a href="https://drive.google.com/file/d/1ntNE7156IF8xJbeyunUeYC1zodAVuYcb/view?usp=sharing">w10_s</a></td>
            <td><a href="https://colab.research.google.com/drive/1FPYyzOxQsCtsehyjq63p6qF0x96wGWZR?usp=sharing">stable_diff</a></td>
            <td><a href="https://www.youtube.com/watch?v=HoKDTa5jHvg">[1]</a> <a href=""></a></td>
        </tr>
        <tr>
            <td style="text-align: center;"> <b>w11</b> </td>
            <td rowspan=1> Introduction to Large Language Models (LLMs) </td>
            <td><a href="https://drive.google.com/file/d/1t8A_hXAPg4li8sZ1TWjol5Bmlu-R38h2/view?usp=sharing">intro_llms</a></td>
 			  <td><a href=""></a></td>
            <td><a href="https://colab.research.google.com/drive/1hUuTE-EQoogIvAy_7CQNLI4l9ot9dKu8?usp=sharing">n1</a>
            <a href="https://colab.research.google.com/drive/1lZNpXo6EPCkcJzYm6YxoN3DA2eUmRT6k?usp=sharing">n2</a>
            <a href="https://colab.research.google.com/drive/1WrmNCCQtK_nhObHOJ7PiaRspDzVJi6Ie?usp=sharing">n3</a></td>
            <td><a href=""></a> <a href=""></a></td>
        </tr>
        <tr>
            <th colspan=7> Graduation Homework </th>
        </tr>
    </tbody>
</table>

# Acknowledgements
Our beloved contributors:

<ul>
  <li>Berfin Duman</li>
  <li>Bike Sönmez</li>
  <li>Deniz Berkin Kahya</li>
  <li>Emir Erman Faruk</li>
  <li>Gürkan Soykan</li>
  <li>İrem Gülçin Zırhlıoğlu</li>
  <li>Melih Darcan</li>
  <li>Sarper Yurtseven</li>
  <li>Simge Şengül</li>
  <li>Şafak Bilici</li>
  <li>Şilan Fidan Vural</li>
  <li>Tarık Can Özden</li>
</ul>


A huge thank you to everyone who spent their time and energy into making the inzva Deep Learning Study Group a reality! Whether you were creating notebooks, prepare presentations, or creating our bundles your efforts have made this journey so much more impactful for everyone involved. We're so grateful to have such an amazing, supportive community making all of this possible. Thank you for being part of this journey and helping it grow!

inzva AI Team

