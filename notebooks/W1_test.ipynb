{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "from neural_network import MLP\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = MLP(input_size=28*28, output_size=10)\n",
    "model.load_state_dict(torch.load('/path/to/your/model'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('/path/to/your/image', cv2.IMREAD_GRAYSCALE) #Read image grayscale\n",
    "scaled_image = cv2.resize(image, (28,28)) #Resize your image to 28x28 (FMNIST shape)\n",
    "scaled_image = torch.from_numpy(scaled_image) #Convert numpy array to torch tensor\n",
    "scaled_image = scaled_image.unsqueeze(dim=0).float().to(device) #Unsqueeze dimension, convert float tensor and move to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use with torch.no_grad for inference (Probably no harm if you don't use but use it...)\n",
    "with torch.no_grad():\n",
    "    output = model(scaled_image.view(scaled_image.size(0), -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Softmax Layer**\n",
    "\n",
    "The Softmax layer is commonly used as the final layer in neural networks for multi-class classification tasks. It converts the raw output scores (logits) from the network into a probability distribution, where each class is assigned a probability between 0 and 1, and the sum of all probabilities equals 1.\n",
    "\n",
    "### **How it works:**\n",
    "\n",
    "Given a vector of logits \\( z \\) (the unnormalized raw scores for each class), the Softmax function computes the probability for each class using the following formula:\n",
    "\n",
    "\n",
    "$\\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}}$\n",
    "\n",
    "Where:\n",
    "- \\( z_i \\) is the logit or raw score for the \\( i \\)-th class.\n",
    "- \\( K \\) is the total number of classes.\n",
    "\n",
    "This formula ensures that each \\( z_i \\) is transformed into a probability, and the sum of all transformed values equals 1, making it a valid probability distribution.\n",
    "\n",
    "### **Why use Softmax:**\n",
    "\n",
    "1. **Normalization**: Softmax converts raw scores into probabilities that are easy to interpret and compare.\n",
    "2. **Multi-class Classification**: In a classification problem with multiple classes, Softmax helps assign the most likely class by choosing the one with the highest probability.\n",
    "\n",
    "### **Example:**\n",
    "\n",
    "Consider a model output with three raw logits for three classes: [2.0, 1.0, 0.1]. The Softmax function would convert these into a probability distribution:\n",
    "\n",
    "1. Compute the exponentials: \\( e^2.0, e^1.0, e^{0.1} \\)\n",
    "2. Normalize these values by dividing each exponential by their sum.\n",
    "\n",
    "The result might be something like [0.65, 0.24, 0.11], indicating that the model assigns a 65% probability to the first class, 24% to the second, and 11% to the third.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.nn.functional.softmax(output, dim=1) # You can get probabilities using softmax \n",
    "predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "classes = FashionMNIST.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scaled_image.cpu().detach().numpy().squeeze(), cmap='gray')\n",
    "plt.title(f'Actual Label: T-shirt/top\\nPredicted Label:{classes[predicted_class]}')\n",
    "plt.savefig('gray_tisort.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Would you like to try on something else?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
