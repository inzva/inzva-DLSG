{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1bea9ca",
   "metadata": {},
   "source": [
    "# **PyTorch Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71221bc6",
   "metadata": {},
   "source": [
    "## **Introduction to PyTorch**\n",
    "PyTorch is a deep learning library that enables developers to build and train neural networks with flexibility and ease. It provides tools to create tensors, define computational graphs, and run models on GPUs for faster computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89831b7f",
   "metadata": {},
   "source": [
    "### **Installing PyTorch**\n",
    "Before diving into PyTorch, we need to install it. You can install it using `pip`:\n",
    "```bash\n",
    "pip install torch torchvision\n",
    "```\n",
    "or refer <a>https://pytorch.org/get-started/locally/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38775224",
   "metadata": {},
   "source": [
    "### **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "643505be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d29fa3",
   "metadata": {},
   "source": [
    "## **PyTorch Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa69efb5",
   "metadata": {},
   "source": [
    "### **Tensors**\n",
    "Tensors are the core data structure in PyTorch. They are similar to NumPy arrays but with the advantage of being able to run on GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359e1b24",
   "metadata": {},
   "source": [
    "#### **Creating Tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49e5c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0.9090, 0.6202, 0.3061],\n",
      "        [0.6875, 0.4972, 0.4581]])\n"
     ]
    }
   ],
   "source": [
    "# Creating a tensor\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(x)\n",
    "\n",
    "# Creating a tensor of zeros\n",
    "x_zeros = torch.zeros((2, 3))\n",
    "print(x_zeros)\n",
    "\n",
    "# Creating a tensor of random values\n",
    "x_rand = torch.rand((2, 3))\n",
    "print(x_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07cc910",
   "metadata": {},
   "source": [
    "#### **Tensor Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91d15a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3, 4],\n",
      "        [6, 7, 8]])\n",
      "tensor([[ 6, 12],\n",
      "        [15, 30]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Basic operations\n",
    "y = torch.tensor([[1, 1, 1], [2, 2, 2]])\n",
    "result = x + y\n",
    "print(result)\n",
    "\n",
    "# Matrix multiplication\n",
    "result_mul = torch.matmul(x, y.T)\n",
    "print(result_mul)\n",
    "\n",
    "# Reshaping a tensor\n",
    "x_reshaped = x.view(3, 2)\n",
    "print(x_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd81538",
   "metadata": {},
   "source": [
    "### **GPU Acceleration**\n",
    "If you have a GPU, you can easily move tensors to the GPU for faster computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac62edba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Moving tensor to GPU\n",
    "x_gpu = x.to(device)\n",
    "print(x_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e03c089",
   "metadata": {},
   "source": [
    "## **Building a Simple Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7953381c",
   "metadata": {},
   "source": [
    "### **Defining a Model**\n",
    "In PyTorch, models are defined using the `nn.Module` class. Let's create a simple neural network for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41cd52c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleNN, self).__init__(),\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e93022",
   "metadata": {},
   "source": [
    "### **Loss Function and Optimizer**\n",
    "To train the model, we need to define a loss function and an optimizer. PyTorch provides several options, and we will use Cross Entropy Loss and the SGD optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7a02b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = SimpleNN(input_size=28*28, output_size=10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ba86b",
   "metadata": {},
   "source": [
    "## **Training the Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458c4db4",
   "metadata": {},
   "source": [
    "### **Loading Data**\n",
    "We will use the MNIST dataset for training, which consists of 28x28 grayscale images of handwritten digits. PyTorch provides `torchvision.datasets` to handle datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48521736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:03<00:00, 2729832.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 246041.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 1959502.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4036128.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb547c5",
   "metadata": {},
   "source": [
    "### **Training Loop**\n",
    "The training loop involves iterating over the dataset, performing forward passes, calculating loss, and updating model parameters using backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d55df380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.2865\n",
      "Epoch [2/5], Loss: 0.1177\n",
      "Epoch [3/5], Loss: 0.0796\n",
      "Epoch [4/5], Loss: 0.0614\n",
      "Epoch [5/5], Loss: 0.0464\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        # Flatten the images\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        # Forward prop\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Compute gradients and update weights (Backward propagation)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414b389a",
   "metadata": {},
   "source": [
    "## **Evaluating the Model**\n",
    "After training, we need to evaluate the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a7c49bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.65%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()  # Set model to evaluation mode (We mentioned at the class but read the document again for why we use it.)\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68df7ce",
   "metadata": {},
   "source": [
    "## **Visualizing Results**\n",
    "### **Visualizing Predictions**\n",
    "We can visualize some of the model's predictions along with the actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25088a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get some test images and labels\n",
    "images, labels = next(iter(test_loader))\n",
    "\n",
    "# Predict the labels\n",
    "images_flat = images.view(images.shape[0], -1)\n",
    "outputs = model(images_flat)\n",
    "_, predictions = torch.max(outputs, 1)\n",
    "\n",
    "# Visualize images with predicted labels\n",
    "fig, axes = plt.subplots(1, 6, figsize=(12, 6))\n",
    "for i in range(6):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(images[i].squeeze(), cmap='gray')\n",
    "    ax.set_title(f'Label: {labels[i]}, Pred: {predictions[i]}')\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f369589",
   "metadata": {},
   "source": [
    "## **Saving and Loading Models**\n",
    "Once a model is trained, it's important to save it for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be4a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'simple_nn.pth')\n",
    "\n",
    "# Load the model\n",
    "model = SimpleNN()\n",
    "model.load_state_dict(torch.load('simple_nn.pth'))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
